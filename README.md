INFO - haystack.modeling.evaluation.eval -

\\|//       \\|//      \\|//       \\|//     \\|//

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*

\*\*\*\*\* EVALUATION | DEV SET | AFTER 12000 BATCHES \*\*\*\*\*

\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*\*

\\|//       \\|//      \\|//       \\|//     \\|//

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

INFO - haystack.modeling.evaluation.eval -

\_\_\_\_\_\_\_\_\_ text\_similarity \_\_\_\_\_\_\_\_\_

INFO - haystack.modeling.evaluation.eval -  loss: 0.04225207879893027

INFO - haystack.modeling.evaluation.eval -  task\_name: text\_similarity

INFO - haystack.modeling.evaluation.eval -  acc: 0.9928042328042328

INFO - haystack.modeling.evaluation.eval -  f1: 0.8849407783417935

INFO - haystack.modeling.evaluation.eval -  acc\_and\_f1: 0.9388725055730132

INFO - haystack.modeling.evaluation.eval -  average\_rank: 0.24027072758037224

INFO - haystack.modeling.evaluation.eval -  report:

precision    recall  f1-score   support

hard\_negative     0.9963    0.9963    0.9963    183090

positive     0.8849    0.8849    0.8849      5910

accuracy                         0.9928    189000

macro avg     0.9406    0.9406    0.9406    189000

weighted avg     0.9928    0.9928    0.9928    189000
